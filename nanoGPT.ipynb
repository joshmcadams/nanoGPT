{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNil65gOHuJVOi34y5/5/Iz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshmcadams/nanoGPT/blob/main/nanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nanoGPT"
      ],
      "metadata": {
        "id": "AfzhVUNsm6yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nanoGPT is a wonderful exploration into building a GPT model from scratch. We'll start with an empty notebook and quickly build and train a model to generate Shakespeare-like text.\n",
        "\n",
        "This notebook is based off of a code and videos releasted by Andrej Karpathy. Please be sure to check out his work!\n",
        "\n",
        "  * [Reference Video Lecture](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
        "  * [Reference Git Repository](https://github.com/karpathy/ng-video-lecture)"
      ],
      "metadata": {
        "id": "0R5juEnSnABo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and Preparation"
      ],
      "metadata": {
        "id": "sHvhw5YXotHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acquiring the data"
      ],
      "metadata": {
        "id": "k6YgbsEVo3BE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll first pull the data down into this lab. To get the data the `wget` command will be used in the shell."
      ],
      "metadata": {
        "id": "agEnmOPeo46n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffHXHUq9pGTf",
        "outputId": "df192102-f7ad-4ed5-b442-d8aa2445133e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-23 23:28:13--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-03-23 23:28:13 (17.6 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll load the data into Python and take a look at a sample."
      ],
      "metadata": {
        "id": "s8L7q9zLpNfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we simply open the file and store the entire contents of the file in the variable `raw_training_data`. We get the length of the data and print that out so that we can see how much data we are dealing with."
      ],
      "metadata": {
        "id": "GhKBNFmnqBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    raw_training_data = f.read()\n",
        "\n",
        "training_data_size = len(raw_training_data)\n",
        "print(training_data_size)"
      ],
      "metadata": {
        "id": "89fV4YklpUvh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we sample the data just to get an idea of what we are dealing with. The sample comes from a random locaiton in the data. Run the code block below a few times to see some different data samples."
      ],
      "metadata": {
        "id": "uDj696OuqXdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "SAMPLE_SIZE = 500\n",
        "start = random.randrange(0, training_data_size - SAMPLE_SIZE)\n",
        "print(raw_training_data[start:start+SAMPLE_SIZE])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PaomKtIpZWH",
        "outputId": "252a8f00-ead4-4447-dc88-f2b70ea18a1b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "PAULINA:\n",
            "I pray now, call her.\n",
            "Withdraw yourselves.\n",
            "\n",
            "Gaoler:\n",
            "And, madam,\n",
            "I must be present at your conference.\n",
            "\n",
            "PAULINA:\n",
            "Well, be't so, prithee.\n",
            "Here's such ado to make no stain a stain\n",
            "As passes colouring.\n",
            "Dear gentlewoman,\n",
            "How fares our gracious lady?\n",
            "\n",
            "EMILIA:\n",
            "As well as one so great and so forlorn\n",
            "May hold together: on her frights and griefs,\n",
            "Which never tender lady hath born greater,\n",
            "She is something before her time deliver'd.\n",
            "\n",
            "PAULINA:\n",
            "A boy?\n",
            "\n",
            "EMILIA:\n",
            "A daughter, and a goodly babe,\n",
            "Lusty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "AqrIITOTrJah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've now acquired the data and even poked around a bit to see what the data looks like. However, we need to dig deeper and do some more detailed analysis on the data."
      ],
      "metadata": {
        "id": "cJ9f9lIerRpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One important fact to know about data that will be fed into a generative model is how many different characters are we working with. This is actually really easy in Python and can be accomplished using the `set` function."
      ],
      "metadata": {
        "id": "CQm6MowVrgQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = sorted(list(set(raw_training_data)))\n",
        "token_count = len(tokens)\n",
        "\n",
        "print(f'There are {token_count} unique characters in the {training_data_size}' +\n",
        "      f'of training data. The characters are: {\"\".join(tokens)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEDbtcArrfx_",
        "outputId": "68a0ce75-2706-41ab-89f0-78ea296ad574"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 65 unique characters in the 1115394of training data. The characters are: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    }
  ]
}