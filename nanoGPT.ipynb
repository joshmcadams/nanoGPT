{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwd6wTVqCpVLaxaQDfQAzp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshmcadams/nanoGPT/blob/main/nanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nanoGPT"
      ],
      "metadata": {
        "id": "AfzhVUNsm6yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nanoGPT is a wonderful exploration into building a GPT model from scratch. We'll start with an empty notebook and quickly build and train a model to generate Shakespeare-like text.\n",
        "\n",
        "This notebook is based off of a code and videos releasted by Andrej Karpathy. Please be sure to check out his work!\n",
        "\n",
        "  * [Reference Video Lecture](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
        "  * [Reference Git Repository](https://github.com/karpathy/ng-video-lecture)"
      ],
      "metadata": {
        "id": "0R5juEnSnABo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and Preparation"
      ],
      "metadata": {
        "id": "sHvhw5YXotHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acquiring the data"
      ],
      "metadata": {
        "id": "k6YgbsEVo3BE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll first pull the data down into this lab. To get the data the `wget` command will be used in the shell."
      ],
      "metadata": {
        "id": "agEnmOPeo46n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffHXHUq9pGTf",
        "outputId": "df192102-f7ad-4ed5-b442-d8aa2445133e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-23 23:28:13--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-03-23 23:28:13 (17.6 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll load the data into Python and take a look at a sample."
      ],
      "metadata": {
        "id": "s8L7q9zLpNfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we simply open the file and store the entire contents of the file in the variable `raw_training_data`. We get the length of the data and print that out so that we can see how much data we are dealing with."
      ],
      "metadata": {
        "id": "GhKBNFmnqBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    raw_training_data = f.read()\n",
        "\n",
        "training_data_size = len(raw_training_data)\n",
        "print(training_data_size)"
      ],
      "metadata": {
        "id": "89fV4YklpUvh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we sample the data just to get an idea of what we are dealing with. The sample comes from a random locaiton in the data. Run the code block below a few times to see some different data samples."
      ],
      "metadata": {
        "id": "uDj696OuqXdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "SAMPLE_SIZE = 500\n",
        "start = random.randrange(0, training_data_size - SAMPLE_SIZE)\n",
        "print(raw_training_data[start:start+SAMPLE_SIZE])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PaomKtIpZWH",
        "outputId": "252a8f00-ead4-4447-dc88-f2b70ea18a1b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "PAULINA:\n",
            "I pray now, call her.\n",
            "Withdraw yourselves.\n",
            "\n",
            "Gaoler:\n",
            "And, madam,\n",
            "I must be present at your conference.\n",
            "\n",
            "PAULINA:\n",
            "Well, be't so, prithee.\n",
            "Here's such ado to make no stain a stain\n",
            "As passes colouring.\n",
            "Dear gentlewoman,\n",
            "How fares our gracious lady?\n",
            "\n",
            "EMILIA:\n",
            "As well as one so great and so forlorn\n",
            "May hold together: on her frights and griefs,\n",
            "Which never tender lady hath born greater,\n",
            "She is something before her time deliver'd.\n",
            "\n",
            "PAULINA:\n",
            "A boy?\n",
            "\n",
            "EMILIA:\n",
            "A daughter, and a goodly babe,\n",
            "Lusty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "AqrIITOTrJah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've now acquired the data and even poked around a bit to see what the data looks like. However, we need to dig deeper and do some more detailed analysis on the data."
      ],
      "metadata": {
        "id": "cJ9f9lIerRpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One important fact to know about data that will be fed into a generative model is how many different characters are we working with. This is actually really easy in Python and can be accomplished using the `set` function."
      ],
      "metadata": {
        "id": "CQm6MowVrgQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = sorted(list(set(raw_training_data)))\n",
        "token_count = len(tokens)\n",
        "\n",
        "print(f'There are {token_count} unique characters in the {training_data_size}' +\n",
        "      f'of training data. The characters are: {\"\".join(tokens)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEDbtcArrfx_",
        "outputId": "68a0ce75-2706-41ab-89f0-78ea296ad574"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 65 unique characters in the 1115394of training data. The characters are: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding"
      ],
      "metadata": {
        "id": "jwLBJJ2TtP7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now know how many different unique tokens exist in our training data. In our case, these tokens will be individual characters, but this a choice that we have made. We could have alternatively chosen pairs, triplets, or some other combination of characters to be a token.\n",
        "\n",
        "Regardless of the data that comprises our tokens, the token itself isn't what we feed to the model. Instead, we need to convert the token into a numeric representation since models are performing numeric calculations internally.\n",
        "\n",
        "For our character-based tokens we could just use the ASCII value of the character using the `ord` function. However, you might eventually want to expermiment with sequences of characters as tokens, and in this case you'll need a more complex token-to-number mapping, so lets just create a token-to-number mapping scheme now.\n",
        "\n",
        "Since we ordered our unique tokens into the `tokens` list, we can just use the index of the token in the list as the encoding, which is what we do.\n",
        "\n",
        "Note that this does come with some trade-offs though. The position of any given token in the list of tokens is relative to how many and what were the unique tokens in the training data. If we use different trianing data, the tokens might map to different indexes so we need to be careful to preserve our tokens across training data set if we are using mulitple different pieces of training data.\n",
        "\n",
        "Anyway, let's write a token-to-number `encode` function and a number-to-token `decode` function."
      ],
      "metadata": {
        "id": "eENRH2pytS-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, create a mapping of tokens to numbers."
      ],
      "metadata": {
        "id": "x1ybdTibvhg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_number = {t: i for i, t in enumerate(tokens)}\n",
        "token_to_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO-Y4yjkvNM3",
        "outputId": "541bb65e-ea16-4540-9dec-1b6a6239f354"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then a mapping from numbers to tokens."
      ],
      "metadata": {
        "id": "C3PcZhzXvyzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_to_token = {i: t for i, t in enumerate(tokens)}\n",
        "number_to_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjOQwnVGvtBE",
        "outputId": "1bf60517-690e-4fb5-aee9-aa86b70684b6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '$',\n",
              " 4: '&',\n",
              " 5: \"'\",\n",
              " 6: ',',\n",
              " 7: '-',\n",
              " 8: '.',\n",
              " 9: '3',\n",
              " 10: ':',\n",
              " 11: ';',\n",
              " 12: '?',\n",
              " 13: 'A',\n",
              " 14: 'B',\n",
              " 15: 'C',\n",
              " 16: 'D',\n",
              " 17: 'E',\n",
              " 18: 'F',\n",
              " 19: 'G',\n",
              " 20: 'H',\n",
              " 21: 'I',\n",
              " 22: 'J',\n",
              " 23: 'K',\n",
              " 24: 'L',\n",
              " 25: 'M',\n",
              " 26: 'N',\n",
              " 27: 'O',\n",
              " 28: 'P',\n",
              " 29: 'Q',\n",
              " 30: 'R',\n",
              " 31: 'S',\n",
              " 32: 'T',\n",
              " 33: 'U',\n",
              " 34: 'V',\n",
              " 35: 'W',\n",
              " 36: 'X',\n",
              " 37: 'Y',\n",
              " 38: 'Z',\n",
              " 39: 'a',\n",
              " 40: 'b',\n",
              " 41: 'c',\n",
              " 42: 'd',\n",
              " 43: 'e',\n",
              " 44: 'f',\n",
              " 45: 'g',\n",
              " 46: 'h',\n",
              " 47: 'i',\n",
              " 48: 'j',\n",
              " 49: 'k',\n",
              " 50: 'l',\n",
              " 51: 'm',\n",
              " 52: 'n',\n",
              " 53: 'o',\n",
              " 54: 'p',\n",
              " 55: 'q',\n",
              " 56: 'r',\n",
              " 57: 's',\n",
              " 58: 't',\n",
              " 59: 'u',\n",
              " 60: 'v',\n",
              " 61: 'w',\n",
              " 62: 'x',\n",
              " 63: 'y',\n",
              " 64: 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we can write our encoder."
      ],
      "metadata": {
        "id": "hVd0DxSKv2-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(tokens: str) -> list[int]:\n",
        "  return [token_to_number[t] for t in tokens]\n",
        "\n",
        "encode('apple')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "775B6Tbov2ux",
        "outputId": "c6065a8e-2dae-4e04-efb8-59dbfdc9cc1b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39, 54, 54, 50, 43]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the decoder."
      ],
      "metadata": {
        "id": "5RrUVwhlwEB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(numbers: list[int]) -> str:\n",
        "  return ''.join(number_to_token[n] for n in numbers)\n",
        "\n",
        "decode([16, 17, 18])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dfDycwx5wGWF",
        "outputId": "6ad80f5c-850d-46b6-b07a-08630291de81"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DEF'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}