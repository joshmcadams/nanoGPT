{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKYnClqjG9BmFjuxMJ3GYX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshmcadams/nanoGPT/blob/main/nanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nanoGPT"
      ],
      "metadata": {
        "id": "AfzhVUNsm6yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nanoGPT is a wonderful exploration into building a GPT model from scratch. We'll start with an empty notebook and quickly build and train a model to generate Shakespeare-like text.\n",
        "\n",
        "This notebook is based off of a code and videos releasted by Andrej Karpathy. Please be sure to check out his work!\n",
        "\n",
        "  * [Reference Video Lecture](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
        "  * [Reference Git Repository](https://github.com/karpathy/ng-video-lecture)"
      ],
      "metadata": {
        "id": "0R5juEnSnABo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and Preparation"
      ],
      "metadata": {
        "id": "sHvhw5YXotHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acquiring the data"
      ],
      "metadata": {
        "id": "k6YgbsEVo3BE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll first pull the data down into this lab. To get the data the `wget` command will be used in the shell."
      ],
      "metadata": {
        "id": "agEnmOPeo46n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffHXHUq9pGTf",
        "outputId": "c23b6486-11b5-4f10-d2ab-6aa6a748ff9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-11 18:18:33--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-05-11 18:18:33 (15.1 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll load the data into Python and take a look at a sample."
      ],
      "metadata": {
        "id": "s8L7q9zLpNfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we simply open the file and store the entire contents of the file in the variable `raw_training_data`. We get the length of the data and print that out so that we can see how much data we are dealing with."
      ],
      "metadata": {
        "id": "GhKBNFmnqBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    raw_training_data = f.read()\n",
        "\n",
        "training_data_size = len(raw_training_data)\n",
        "print(training_data_size)"
      ],
      "metadata": {
        "id": "89fV4YklpUvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb16c36-5ef7-4886-cec8-c4119ac49bde"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we sample the data just to get an idea of what we are dealing with. The sample comes from a random locaiton in the data. Run the code block below a few times to see some different data samples."
      ],
      "metadata": {
        "id": "uDj696OuqXdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "SAMPLE_SIZE = 500\n",
        "start = random.randrange(0, training_data_size - SAMPLE_SIZE)\n",
        "print(raw_training_data[start:start+SAMPLE_SIZE])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PaomKtIpZWH",
        "outputId": "11fb73f8-6db6-4c83-85c9-e64cf5504ca6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", ere I go, Hastings and Montague,\n",
            "Resolve my doubt. You twain, of all the rest,\n",
            "Are near to Warwick by blood and by alliance:\n",
            "Tell me if you love Warwick more than me?\n",
            "If it be so, then both depart to him;\n",
            "I rather wish you foes than hollow friends:\n",
            "But if you mind to hold your true obedience,\n",
            "Give me assurance with some friendly vow,\n",
            "That I may never have you in suspect.\n",
            "\n",
            "MONTAGUE:\n",
            "So God help Montague as he proves true!\n",
            "\n",
            "HASTINGS:\n",
            "And Hastings as he favours Edward's cause!\n",
            "\n",
            "KING EDWARD IV:\n",
            "No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis"
      ],
      "metadata": {
        "id": "AqrIITOTrJah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've now acquired the data and even poked around a bit to see what the data looks like. However, we need to dig deeper and do some more detailed analysis on the data."
      ],
      "metadata": {
        "id": "cJ9f9lIerRpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One important fact to know about data that will be fed into a generative model is how many different characters are we working with. This is actually really easy in Python and can be accomplished using the `set` function."
      ],
      "metadata": {
        "id": "CQm6MowVrgQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = sorted(list(set(raw_training_data)))\n",
        "token_count = len(tokens)\n",
        "\n",
        "print(f'There are {token_count} unique characters in the {training_data_size}' +\n",
        "      f'of training data. The characters are: {\"\".join(tokens)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEDbtcArrfx_",
        "outputId": "e68dd674-55f8-45fa-f0c6-44dbc2bc3997"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 65 unique characters in the 1115394of training data. The characters are: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding"
      ],
      "metadata": {
        "id": "jwLBJJ2TtP7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now know how many different unique tokens exist in our training data. In our case, these tokens will be individual characters, but this a choice that we have made. We could have alternatively chosen pairs, triplets, or some other combination of characters to be a token.\n",
        "\n",
        "Regardless of the data that comprises our tokens, the token itself isn't what we feed to the model. Instead, we need to convert the token into a numeric representation since models are performing numeric calculations internally.\n",
        "\n",
        "For our character-based tokens we could just use the ASCII value of the character using the `ord` function. However, you might eventually want to expermiment with sequences of characters as tokens, and in this case you'll need a more complex token-to-number mapping, so lets just create a token-to-number mapping scheme now.\n",
        "\n",
        "Since we ordered our unique tokens into the `tokens` list, we can just use the index of the token in the list as the encoding, which is what we do.\n",
        "\n",
        "Note that this does come with some trade-offs though. The position of any given token in the list of tokens is relative to how many and what were the unique tokens in the training data. If we use different trianing data, the tokens might map to different indexes so we need to be careful to preserve our tokens across training data set if we are using mulitple different pieces of training data.\n",
        "\n",
        "Anyway, let's write a token-to-number `encode` function and a number-to-token `decode` function."
      ],
      "metadata": {
        "id": "eENRH2pytS-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, create a mapping of tokens to numbers."
      ],
      "metadata": {
        "id": "x1ybdTibvhg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_number = {t: i for i, t in enumerate(tokens)}\n",
        "token_to_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO-Y4yjkvNM3",
        "outputId": "bceb3741-3365-43cd-d967-40b710c5b8e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then a mapping from numbers to tokens."
      ],
      "metadata": {
        "id": "C3PcZhzXvyzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_to_token = {i: t for i, t in enumerate(tokens)}\n",
        "number_to_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjOQwnVGvtBE",
        "outputId": "6881e738-2108-4b6a-b4cc-087f0ba932fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '$',\n",
              " 4: '&',\n",
              " 5: \"'\",\n",
              " 6: ',',\n",
              " 7: '-',\n",
              " 8: '.',\n",
              " 9: '3',\n",
              " 10: ':',\n",
              " 11: ';',\n",
              " 12: '?',\n",
              " 13: 'A',\n",
              " 14: 'B',\n",
              " 15: 'C',\n",
              " 16: 'D',\n",
              " 17: 'E',\n",
              " 18: 'F',\n",
              " 19: 'G',\n",
              " 20: 'H',\n",
              " 21: 'I',\n",
              " 22: 'J',\n",
              " 23: 'K',\n",
              " 24: 'L',\n",
              " 25: 'M',\n",
              " 26: 'N',\n",
              " 27: 'O',\n",
              " 28: 'P',\n",
              " 29: 'Q',\n",
              " 30: 'R',\n",
              " 31: 'S',\n",
              " 32: 'T',\n",
              " 33: 'U',\n",
              " 34: 'V',\n",
              " 35: 'W',\n",
              " 36: 'X',\n",
              " 37: 'Y',\n",
              " 38: 'Z',\n",
              " 39: 'a',\n",
              " 40: 'b',\n",
              " 41: 'c',\n",
              " 42: 'd',\n",
              " 43: 'e',\n",
              " 44: 'f',\n",
              " 45: 'g',\n",
              " 46: 'h',\n",
              " 47: 'i',\n",
              " 48: 'j',\n",
              " 49: 'k',\n",
              " 50: 'l',\n",
              " 51: 'm',\n",
              " 52: 'n',\n",
              " 53: 'o',\n",
              " 54: 'p',\n",
              " 55: 'q',\n",
              " 56: 'r',\n",
              " 57: 's',\n",
              " 58: 't',\n",
              " 59: 'u',\n",
              " 60: 'v',\n",
              " 61: 'w',\n",
              " 62: 'x',\n",
              " 63: 'y',\n",
              " 64: 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we can write our encoder."
      ],
      "metadata": {
        "id": "hVd0DxSKv2-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(tokens: str) -> list[int]:\n",
        "  return [token_to_number[t] for t in tokens]\n",
        "\n",
        "encode('apple')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "775B6Tbov2ux",
        "outputId": "9e87f26a-7752-41a2-9f23-9cc6ed67ab4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39, 54, 54, 50, 43]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the decoder."
      ],
      "metadata": {
        "id": "5RrUVwhlwEB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(numbers: list[int]) -> str:\n",
        "  return ''.join(number_to_token[n] for n in numbers)\n",
        "\n",
        "decode([16, 17, 18])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dfDycwx5wGWF",
        "outputId": "5447c00e-d8c1-47f2-cb9e-59186789e923"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DEF'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a tokenizer and a large amount of text. Let's tokenize all the text!\n",
        "\n",
        "[Video Reference Point](https://youtu.be/kCc8FmEb1nY?t=778)"
      ],
      "metadata": {
        "id": "cTdGKKUD5PZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(raw_training_data), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUZ4022h5Z38",
        "outputId": "978de37c-ab97-4290-d7c1-b7351ede8fbe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to split training data and testing data."
      ],
      "metadata": {
        "id": "C6w2aQ4-6IYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_size = int(0.9*len(data))\n",
        "training_data = data[:training_data_size]\n",
        "validation_data = data[training_data_size:]\n",
        "print(len(training_data), len(validation_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYVyMdov6MOF",
        "outputId": "269e2fe7-bfb3-4b27-bc53-2b3fc8613e31"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1003854 111540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time Dimension"
      ],
      "metadata": {
        "id": "N-ktY-_58eLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we work on training in blocks.\n",
        "In this case we train in blocks of 8 characters, but we always need the \"next\" character, so we work with block sizes of bock+1.\n",
        "\n",
        "[Video Reference Point](https://youtu.be/kCc8FmEb1nY?t=913)"
      ],
      "metadata": {
        "id": "8ZdjI7bR7DY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "training_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrxJhNAH7I2u",
        "outputId": "a34087cd-8107-4d04-aa95-2dd56d405f37"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = training_data[:block_size]\n",
        "y = training_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"in: {context}, out: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB3aEKF77jz1",
        "outputId": "c9501d90-6583-48a7-bf10-6086f79621f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in: tensor([18]), out: 47\n",
            "in: tensor([18, 47]), out: 56\n",
            "in: tensor([18, 47, 56]), out: 57\n",
            "in: tensor([18, 47, 56, 57]), out: 58\n",
            "in: tensor([18, 47, 56, 57, 58]), out: 1\n",
            "in: tensor([18, 47, 56, 57, 58,  1]), out: 15\n",
            "in: tensor([18, 47, 56, 57, 58,  1, 15]), out: 47\n",
            "in: tensor([18, 47, 56, 57, 58,  1, 15, 47]), out: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Dimension"
      ],
      "metadata": {
        "id": "XScEDiyd8he6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Video Reference Point](https://youtu.be/kCc8FmEb1nY?t=1129)"
      ],
      "metadata": {
        "id": "SwOcHO4i8sNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "  data = training_data if split == 'train' else validation_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print('----------------------------------')\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'input {context.tolist()}, target {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDrFtzol8l9R",
        "outputId": "12e572d3-9b75-4116-ebc5-7e5c4a0bde27"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----------------------------------\n",
            "input [24], target 43\n",
            "input [24, 43], target 58\n",
            "input [24, 43, 58], target 5\n",
            "input [24, 43, 58, 5], target 57\n",
            "input [24, 43, 58, 5, 57], target 1\n",
            "input [24, 43, 58, 5, 57, 1], target 46\n",
            "input [24, 43, 58, 5, 57, 1, 46], target 43\n",
            "input [24, 43, 58, 5, 57, 1, 46, 43], target 39\n",
            "input [44], target 53\n",
            "input [44, 53], target 56\n",
            "input [44, 53, 56], target 1\n",
            "input [44, 53, 56, 1], target 58\n",
            "input [44, 53, 56, 1, 58], target 46\n",
            "input [44, 53, 56, 1, 58, 46], target 39\n",
            "input [44, 53, 56, 1, 58, 46, 39], target 58\n",
            "input [44, 53, 56, 1, 58, 46, 39, 58], target 1\n",
            "input [52], target 58\n",
            "input [52, 58], target 1\n",
            "input [52, 58, 1], target 58\n",
            "input [52, 58, 1, 58], target 46\n",
            "input [52, 58, 1, 58, 46], target 39\n",
            "input [52, 58, 1, 58, 46, 39], target 58\n",
            "input [52, 58, 1, 58, 46, 39, 58], target 1\n",
            "input [52, 58, 1, 58, 46, 39, 58, 1], target 46\n",
            "input [25], target 17\n",
            "input [25, 17], target 27\n",
            "input [25, 17, 27], target 10\n",
            "input [25, 17, 27, 10], target 0\n",
            "input [25, 17, 27, 10, 0], target 21\n",
            "input [25, 17, 27, 10, 0, 21], target 1\n",
            "input [25, 17, 27, 10, 0, 21, 1], target 54\n",
            "input [25, 17, 27, 10, 0, 21, 1, 54], target 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiGram"
      ],
      "metadata": {
        "id": "w2bRuY9s-3KA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Video Reference Point](https://youtu.be/kCc8FmEb1nY?t=1348)\n",
        "\n",
        "[Makemore Series covering the BiGram language model](https://www.youtube.com/watch?v=PaCmpygFfXo)"
      ],
      "metadata": {
        "id": "RN-o8VBS-7PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets):\n",
        "    logits = self.token_embedding_table(idx)\n",
        "\n",
        "    B, T, C = logits.shape\n",
        "    logits = logits.view(B*T, C)\n",
        "    targets = targets.view(B*T)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "m = BigramLanguageModel(token_count)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssEOig2v-4rF",
        "outputId": "576f273f-c153-4003-e5e0-9f7513d66bcb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(-np.log(1/65.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMXTrz6PCMoC",
        "outputId": "df0f26c4-2229-413d-cf72-ff5e26c71e0a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.174387269895637\n"
          ]
        }
      ]
    }
  ]
}